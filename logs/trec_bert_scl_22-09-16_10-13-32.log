> creating model bert
> cuda memory allocated: 439088640
> training arguments:
>>> data_dir: data
>>> dataset: trec
>>> model_name: bert
>>> method: scl
>>> train_batch_size: 16
>>> test_batch_size: 64
>>> num_epoch: 100
>>> lr: 1e-05
>>> decay: 0.01
>>> alpha: 0.5
>>> temp: 0.1
>>> backend: False
>>> timestamp: 1663294412085
>>> device: cuda
>>> num_classes: 6
>>> log_name: trec_bert_scl_22-09-16_10-13-32.log
1/100 - 1.00%
[train] loss: 1.2111, acc: 77.05
[test] loss: 1.4930, acc: 95.80
2/100 - 2.00%
[train] loss: 0.7051, acc: 95.30
[test] loss: 1.4629, acc: 96.80
3/100 - 3.00%
[train] loss: 0.6087, acc: 97.32
[test] loss: 1.4603, acc: 97.00
4/100 - 4.00%
[train] loss: 0.5581, acc: 98.55
[test] loss: 1.4492, acc: 96.80
5/100 - 5.00%
[train] loss: 0.5267, acc: 99.03
[test] loss: 1.4594, acc: 97.20
6/100 - 6.00%
[train] loss: 0.5145, acc: 99.34
[test] loss: 1.4989, acc: 96.80
7/100 - 7.00%
[train] loss: 0.5082, acc: 99.49
[test] loss: 1.4846, acc: 96.80
8/100 - 8.00%
[train] loss: 0.5020, acc: 99.61
[test] loss: 1.4779, acc: 97.20
9/100 - 9.00%
[train] loss: 0.5026, acc: 99.65
[test] loss: 1.5886, acc: 96.40
