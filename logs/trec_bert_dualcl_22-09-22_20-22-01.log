> creating model bert
> cuda memory allocated: 439088640
> training arguments:
>>> data_dir: data
>>> dataset: trec
>>> model_name: bert
>>> method: dualcl
>>> train_batch_size: 16
>>> test_batch_size: 64
>>> num_epoch: 100
>>> lr: 1e-05
>>> decay: 0.01
>>> alpha: 0.5
>>> temp: 0.1
>>> backend: False
>>> timestamp: 1663849322774
>>> device: cuda
>>> num_classes: 6
>>> log_name: trec_bert_dualcl_22-09-22_20-22-01.log
